<html>
<head></head>
<body>
<p><font size="5"><b>Keyword : Task </b></font></p>
<p><font size="4"><b>This keyword is found in the following applications</b></font></p>
<p> 1 STEERABLE, FOLLOW THE LEADER DEVICE by (<a href="Choset.html">Choset</a>,<a href="Howard M..html">Howard M.</a>,<a href="Wolf.html">Wolf</a>,<a href="Alon.html">Alon</a>,<a href="Zenati.html">Zenati</a>,<a href="Marco A..html">Marco A.</a>)</p>
<p>Abstract

 A highly articulated robotic probe (HARP) is comprised of a first
     mechanism and a second mechanism, one or both of which can be steered in
     desired directions. Each mechanism can alternate between being rigid and
     limp. In limp mode the mechanism is highly flexible. When one mechanism
     is limp, the other is rigid. The limp mechanism is then pushed or pulled
     along the rigid mechanism. The limp mechanism is made rigid, thereby
     assuming the shape of the rigid mechanism. The rigid mechanism is made
     limp and the process repeats. These innovations allow the device to drive
     anywhere in three dimensions. The device can "remember" its previous
     configurations, and can go anywhere in a body or other structure (e.g.
     jet engine). When used in medical applications, once the device arrives
     at a desired location, the inner core mechanism can be removed and
     another functional device such as a scalpel, clamp or other tool slid
     through the rigid sleeve to perform. Because of the rules governing
     abstracts, this abstract should not be used to construe the claims.</p>
<p> 2 EMOTION RECOGNITION SYSTEM AND METHOD FOR MODULATING THE BEHAVIOR OF
     INTELLIGENT SYSTEMS by (<a href="Smailagic.html">Smailagic</a>,<a href="Asim.html">Asim</a>,<a href="Siewiorek.html">Siewiorek</a>,<a href="Daniel.html">Daniel</a>)</p>
<p>Abstract

 The disclosure describes an audio-based emotion recognition system that
     is able to classify emotions in real-time. The emotion recognition
     system, according to some embodiments, adjusts the behavior of
     intelligent systems, such as a virtual coach, depending on the user's
     emotion, thereby providing an improved user experience. Embodiments of
     the emotion recognition system and method use short utterances as
     real-time speech from the user and use prosodic and phonetic features,
     such as fundamental frequency, amplitude, and Mel-Frequency Cepstral
     Coefficients, as the main set of features by which the human speech is
     characterized. In addition, certain embodiments of the present invention
     use One-Against-All or Two-Stage classification systems to determine
     different emotions. A minimum-error feature removal mechanism is further
     provided in alternate embodiments to reduce bandwidth and increase
     accuracy of the emotion recognition system.</p>
</body></html>
